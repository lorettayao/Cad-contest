{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lorettayao/Cad-contest.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDrVIfzZnc8i",
        "outputId": "3acdbf78-9d19-4747-bbb4-bb30874fb9e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cad-contest'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 88 (delta 42), reused 74 (delta 34), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (88/88), 1.83 MiB | 5.44 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53I91LrQnoXu",
        "outputId": "97fef069-5111-47ec-ccc5-6caf87841b8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "from scipy.sparse import lil_matrix, save_npz\n",
        "\n",
        "# ===== Step 1: 解析 Verilog 檔案 =====\n",
        "def parse_verilog(verilog_code):\n",
        "    gates = []\n",
        "    primary_inputs = [\"1'b1\",\"1'b0\"]\n",
        "    primary_outputs = []\n",
        "    for line in verilog_code.splitlines():\n",
        "        line = line.strip()\n",
        "        #print(f\"Processing line: {line}\")\n",
        "\n",
        "        if line.startswith('input'):\n",
        "            line = line.strip().rstrip(';')\n",
        "            line = line[len('input'):].strip()\n",
        "\n",
        "            vector_range = None\n",
        "\n",
        "            # Check for vector declaration like [11:0]\n",
        "            if line.startswith('['):\n",
        "                closing_bracket_index = line.find(']')\n",
        "                vector_range_str = line[1:closing_bracket_index]\n",
        "                msb, lsb = map(int, vector_range_str.split(':'))\n",
        "                vector_range = range(lsb, msb + 1) if lsb <= msb else range(lsb, msb - 1, -1)\n",
        "                line = line[closing_bracket_index + 1:].strip()\n",
        "\n",
        "            # Split remaining part into signal names\n",
        "            signals = [name.strip() for name in line.split(',')]\n",
        "\n",
        "            for sig in signals:\n",
        "                if vector_range:\n",
        "                    primary_inputs.extend([f\"{sig}[{i}]\" for i in vector_range])\n",
        "                else:\n",
        "                    primary_inputs.append(sig)\n",
        "\n",
        "        # check if line starts with output, such as: output n6, n7;\n",
        "        # or such as: output [11:0] n8;\n",
        "        # then n6, n7, n8 are primary outputs\n",
        "        if line.startswith('output'):\n",
        "            line = line.strip().rstrip(';')\n",
        "            line = line[len('output'):].strip()\n",
        "\n",
        "            vector_range = None\n",
        "            # Check for vector declaration like [11:0]\n",
        "            if line.startswith('['):\n",
        "                closing_bracket_index = line.find(']')\n",
        "                vector_range_str = line[1:closing_bracket_index]\n",
        "                msb, lsb = map(int, vector_range_str.split(':'))\n",
        "                vector_range = range(lsb, msb + 1) if lsb <= msb else range(lsb, msb - 1, -1)\n",
        "                line = line[closing_bracket_index + 1:].strip()\n",
        "            # Split remaining part into signal names\n",
        "            signals = [name.strip() for name in line.split(',')]\n",
        "            for sig in signals:\n",
        "                if vector_range:\n",
        "                    primary_outputs.extend([f\"{sig}[{i}]\" for i in vector_range])\n",
        "                else:\n",
        "                    primary_outputs.append(sig)\n",
        "\n",
        "        # 解析 BUF gate\n",
        "        buf_match = re.match(r'^\\s*buf\\s+(\\S+)\\((\\S+),\\s*(\\S+)\\);', line)\n",
        "        if buf_match:\n",
        "            gates.append(('BUF', buf_match.group(1), buf_match.group(2), buf_match.group(3)))  # buf, output, input\n",
        "            continue\n",
        "\n",
        "        # 解析 DFF gate（具名端口的 DFF gate，處理 .RN, .SN 等）\n",
        "        dff_match = re.match(r'^\\s*dff\\s+(\\S+)\\s*\\(\\.RN\\(([^)]+)\\),\\s*\\.SN\\(([^)]+)\\),\\s*\\.CK\\(([^)]+)\\),\\s*\\.D\\(([^)]+)\\),\\s*\\.Q\\(([^)]+)\\)\\);', line)\n",
        "        if dff_match:\n",
        "            gates.append(('DFF', dff_match.group(1), dff_match.group(2), dff_match.group(3),\n",
        "                          dff_match.group(4), dff_match.group(5), dff_match.group(6)))  # dff, RN, SN, CK, D, Q\n",
        "            continue\n",
        "\n",
        "        # 解析 OR gate (雙輸入 gate)\n",
        "        or_match = re.match(r'^\\s*or\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if or_match:\n",
        "            gates.append(('OR', or_match.group(1), or_match.group(2), or_match.group(3), or_match.group(4)))  # or, output, input1, input2\n",
        "            continue\n",
        "\n",
        "        # 解析 NOR gate (雙輸入 gate)\n",
        "        nor_match = re.match(r'^\\s*nor\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if nor_match:\n",
        "            gates.append(('NOR', nor_match.group(1), nor_match.group(2), nor_match.group(3), nor_match.group(4)))  # nor, output, input1, input2\n",
        "            continue\n",
        "\n",
        "        # 解析 NOT gate (單輸入 gate)\n",
        "        not_match = re.match(r'^\\s*not\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if not_match:\n",
        "            gates.append(('NOT', not_match.group(1), not_match.group(2), not_match.group(3)))  # not, output, input\n",
        "            continue\n",
        "\n",
        "        # 解析 XOR gate (雙輸入 gate)\n",
        "        xor_match = re.match(r'^\\s*xor\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if xor_match:\n",
        "            gates.append(('XOR', xor_match.group(1), xor_match.group(2), xor_match.group(3), xor_match.group(4)))  # xor, output, input1, input2\n",
        "            continue\n",
        "\n",
        "        # 解析 AND gate (雙輸入 gate)\n",
        "        and_match = re.match(r'^\\s*and\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if and_match:\n",
        "            gates.append(('AND', and_match.group(1), and_match.group(2), and_match.group(3), and_match.group(4)))  # and, output, input1, input2\n",
        "            continue\n",
        "\n",
        "        # 解析 NAND gate (雙輸入 gate)\n",
        "        nand_match = re.match(r'^\\s*nand\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if nand_match:\n",
        "            gates.append(('NAND', nand_match.group(1), nand_match.group(2), nand_match.group(3), nand_match.group(4)))  # nand, output, input1, input2\n",
        "            continue\n",
        "\n",
        "        # 解析 XNOR gate (雙輸入 gate)\n",
        "        xnor_match = re.match(r'^\\s*xnor\\s+(\\S+)\\((\\S+)\\s*,\\s*(\\S+)\\s*,\\s*(\\S+)\\);', line)\n",
        "        if xnor_match:\n",
        "            gates.append(('XNOR', xnor_match.group(1), xnor_match.group(2), xnor_match.group(3), xnor_match.group(4)))  # xor, output, input1, input2\n",
        "            continue\n",
        "    #print(gates)\n",
        "    return gates, primary_inputs, primary_outputs\n",
        "# ===== Step 2: 轉換成 infolist 格式 =====\n",
        "def gates_to_infolist(gates, trojan_gates=[]):\n",
        "    infolist = []\n",
        "    for g in gates:\n",
        "        gtype = g[0]\n",
        "        instname = g[1]\n",
        "        output = g[2]\n",
        "        inputs = list(g[3:])\n",
        "\n",
        "        portnames = ['Y'] + [f'A{i+1}' for i in range(len(inputs))]\n",
        "        connnames = [output] + inputs\n",
        "\n",
        "        is_trojan = (instname in trojan_gates or output in trojan_gates or any(inp in trojan_gates for inp in inputs))\n",
        "        infolist.append((\n",
        "            gtype, gtype, instname, instname, portnames, connnames, is_trojan\n",
        "        ))\n",
        "        #print(\"connnames = \",connnames)\n",
        "    return infolist\n",
        "\n",
        "# ===== Step 3: 建立 adjacency matrix & features =====\n",
        "def build_lookup(infolist):\n",
        "    lookup = {}\n",
        "    for i, info in enumerate(infolist):\n",
        "        conns = info[5]  # connection names\n",
        "        for conn in conns[1:]:  # skip output\n",
        "            if conn not in lookup:\n",
        "                lookup[conn] = []\n",
        "            lookup[conn].append(i)\n",
        "    return lookup\n",
        "\n",
        "def build_graph_features(infolist, primary_inputs=None):\n",
        "    numnodes = len(infolist) + len(primary_inputs)\n",
        "    adj = lil_matrix((numnodes, numnodes), dtype=bool)\n",
        "    class_map = {}\n",
        "    train_indices = list(range(numnodes))  # 全部都當 train\n",
        "\n",
        "    gatelist = sorted(list(set([x[0] for x in infolist])))\n",
        "    gatelookup = {g: i for i, g in enumerate(gatelist)}\n",
        "\n",
        "    # feature: one-hot + in degree + out degree\n",
        "    feats = np.zeros((numnodes, len(gatelist) + 2))\n",
        "    gate_map={}\n",
        "    lookup = build_lookup(infolist)\n",
        "\n",
        "    for i, info in enumerate(infolist):\n",
        "        gatetype = info[0]\n",
        "        conns = info[5]\n",
        "        feats[i][gatelookup[gatetype]] = 1\n",
        "\n",
        "        # Loretta\n",
        "        output_wire = conns[0]  # output wire\n",
        "\n",
        "        if output_wire in lookup:\n",
        "            for j in lookup[output_wire]:\n",
        "                if i != j:\n",
        "                    adj[i, j] = True\n",
        "                    feats[i][-1] += 1  # out degree\n",
        "                    feats[j][-2] += 1  # in degree\n",
        "\n",
        "        class_map[i] = 1 if info[6] else 0\n",
        "        gate_map[i] = info[2]\n",
        "\n",
        "    for i, pi in enumerate(primary_inputs):\n",
        "        if pi not in lookup:\n",
        "            continue\n",
        "        for j, lookup_pi in enumerate(lookup[pi]):\n",
        "            adj[i+len(infolist), lookup_pi] = True # primary input to gate\n",
        "            class_map[i+len(infolist)] = 0  # primary inputs are not trojan\n",
        "            gate_map[i+len(infolist)] = pi\n",
        "\n",
        "    return adj, feats, train_indices, class_map, gate_map\n",
        "\n",
        "# ===== Step 4: 儲存 GraphSAGE 所需格式 =====\n",
        "def save_graphsage_format(adj, feats, class_map, train_indices, gate_map):\n",
        "    save_npz(\"adj_full.npz\", adj.tocsr())\n",
        "    save_npz(\"adj_train.npz\", adj.tocsr())  # 簡化處理：用一樣的\n",
        "\n",
        "    np.save(\"feats.npy\", feats, allow_pickle=False)\n",
        "\n",
        "    with open(\"class_map.json\", \"w\") as f:\n",
        "        json.dump(class_map, f)\n",
        "\n",
        "    with open(\"role.json\", \"w\") as f:\n",
        "        json.dump({'tr': train_indices, 'va': [], 'te': []}, f)\n",
        "\n",
        "    with open(\"gate_map.json\", \"w\") as f:  # <== 新增這段\n",
        "        json.dump(gate_map, f)\n",
        "\n",
        "# ===== 主流程 =====\n",
        "def process_single_verilog(filepath, gt_trojan_filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        code = f.read()\n",
        "\n",
        "    gates, primary_inputs, primary_outputs = parse_verilog(code)\n",
        "    print(f\"Parsed {len(gates)} gates, {primary_inputs} primary inputs, {len(primary_outputs)} primary outputs.\")\n",
        "    # 若無trojan gates, txt只有一行: NO_TROJAN\n",
        "    # 若有trojan gates, txt第一行是 \"TROJANED\", 第二行是 \"TROJAN_GATES\", 最後一行是 \"END_TROJAN_GATES\"\n",
        "    trojan_gates = []\n",
        "    with open(gt_trojan_filepath, 'r') as f:\n",
        "        lines = [l.strip() for l in f]\n",
        "        if lines and lines[0] == \"TROJANED\":\n",
        "            for line in lines[2:]:\n",
        "                if line == \"END_TROJAN_GATES\":\n",
        "                    break\n",
        "                trojan_gates.append(line)\n",
        "        else:\n",
        "            trojan_gates = []\n",
        "    infolist = gates_to_infolist(gates, trojan_gates)\n",
        "    adj, feats, train_indices, class_map, gate_map = build_graph_features(infolist, primary_inputs)\n",
        "    save_graphsage_format(adj, feats, class_map, train_indices, gate_map)\n",
        "\n",
        "    print(\"✅ Graph feature files saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_single_verilog(\"design4.v\", \"result4.txt\")  # 改成你的檔案\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYEne2m4nipF",
        "outputId": "d0a9ca6e-28e9-4168-c95e-17e66f4a8271"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed 3375 gates, [\"1'b1\", \"1'b0\", 'n0', 'n1', 'n2[0]', 'n2[1]', 'n2[2]', 'n2[3]', 'n2[4]', 'n2[5]', 'n2[6]', 'n2[7]', 'n2[8]', 'n2[9]', 'n2[10]', 'n2[11]', 'n2[12]', 'n2[13]', 'n2[14]', 'n2[15]', 'n2[16]', 'n2[17]', 'n2[18]', 'n2[19]', 'n2[20]', 'n2[21]', 'n2[22]', 'n2[23]', 'n2[24]', 'n2[25]', 'n2[26]', 'n2[27]', 'n2[28]', 'n2[29]', 'n2[30]', 'n2[31]', 'n2[32]', 'n2[33]', 'n2[34]', 'n2[35]', 'n2[36]', 'n2[37]', 'n2[38]', 'n2[39]', 'n2[40]', 'n2[41]', 'n2[42]', 'n2[43]', 'n2[44]', 'n2[45]', 'n2[46]', 'n2[47]', 'n2[48]', 'n2[49]', 'n2[50]', 'n2[51]', 'n2[52]', 'n2[53]', 'n2[54]', 'n2[55]', 'n2[56]', 'n2[57]', 'n2[58]', 'n2[59]', 'n2[60]', 'n2[61]', 'n2[62]', 'n2[63]', 'n2[64]', 'n2[65]', 'n2[66]', 'n2[67]', 'n2[68]', 'n2[69]', 'n2[70]', 'n2[71]', 'n2[72]', 'n2[73]', 'n2[74]', 'n2[75]', 'n2[76]', 'n2[77]', 'n2[78]', 'n2[79]', 'n2[80]', 'n2[81]', 'n2[82]', 'n2[83]', 'n2[84]', 'n2[85]', 'n2[86]', 'n2[87]', 'n2[88]', 'n2[89]', 'n2[90]', 'n2[91]', 'n2[92]', 'n2[93]', 'n2[94]', 'n2[95]', 'n2[96]', 'n2[97]', 'n2[98]', 'n2[99]', 'n2[100]', 'n2[101]', 'n2[102]', 'n2[103]', 'n2[104]', 'n2[105]', 'n2[106]', 'n2[107]', 'n2[108]', 'n2[109]', 'n2[110]', 'n2[111]', 'n2[112]', 'n2[113]', 'n2[114]', 'n2[115]', 'n2[116]', 'n2[117]', 'n2[118]', 'n2[119]', 'n2[120]', 'n2[121]', 'n2[122]', 'n2[123]', 'n2[124]', 'n2[125]', 'n2[126]', 'n2[127]'] primary inputs, 192 primary outputs.\n",
            "✅ Graph feature files saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUnHjhz829b",
        "outputId": "b369309b-3d37-434a-817a-5aa44e50ed95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    }
  ]
}